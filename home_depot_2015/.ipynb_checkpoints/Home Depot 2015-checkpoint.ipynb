{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "### TVID transformers for product_title and product_description throw errors because the encoding for those columns is whack (and when i read_csv and encode in encoding=\"ISO-8859-1\" it doesn't pipeline the features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Depot Product Search Relevance\n",
    "The goal of this analysis is to determine how to predict relevance of a search on Home Depot's website. The training data were labelled by crowdsourcing humans, but the hope is that the text and numerical features will be enough to predict relevance via machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import my library stack\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import os\n",
    "import pprint\n",
    "import copy\n",
    "import gc\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Some nice display tools for ipython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# There are several files that the Kaggle competition included for this analysis\n",
    "DATADIR = \"%s/home_depot_2015/\"%os.environ[\"KAGGLE_DATA_DIR\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Overview of the data\n",
    "There are three files I will take a peek at here:\n",
    "    \n",
    "* **train.csv** -- The training set, which contains products, searches, and relevance scores\n",
    "* **test.csv** -- The test set, which contains products and searches --> I am to predict relevance scores\n",
    "    \n",
    "* **product_descriptions.csv** -- Contains product id and a plain text description of the product\n",
    "    \n",
    "* **attributes.csv** -- Contains product id and several attributes, but for only a *subset* of products\n",
    "\n",
    "I'm just going to preview the first few rows of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>First three rows of train</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                      product_title    search_term  \\\n",
       "0   2       100001  Simpson Strong-Tie 12-Gauge Angle  angle bracket   \n",
       "\n",
       "   relevance  \n",
       "0          3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>First three rows of test</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>90 degree bracket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                      product_title        search_term\n",
       "0   1       100001  Simpson Strong-Tie 12-Gauge Angle  90 degree bracket"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>First three rows of descriptions</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                product_description\n",
       "0       100001  Not only do angles make joints stronger, they ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>First three rows of attributes</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Bullet01</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid      name                                              value\n",
       "0       100001  Bullet01  Versatile connector for various 90Â° connectio..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first 5 rows of a csv file given the path to it\n",
    "def preview_data(file, name):\n",
    "    print display(HTML(\"<h3>First three rows of %s</h3>\"%name))\n",
    "    preview_df = pd.read_csv(file, encoding=\"ISO-8859-1\")\n",
    "    print display(preview_df.head(1))\n",
    "\n",
    "def get_path(file):\n",
    "    return \"%s%s\"%(DATADIR, file)\n",
    "\n",
    "# Define the files for later\n",
    "f_train = get_path('train.csv')\n",
    "f_test = get_path('test.csv')\n",
    "f_desc = get_path('product_descriptions.csv')\n",
    "f_attr = get_path('attributes.csv')\n",
    "\n",
    "# Do all four\n",
    "files = [(f_train, 'train'), (f_test, 'test'), (f_desc, 'descriptions'), (f_attr, 'attributes')]\n",
    "map(lambda x: preview_data(x[0], x[1]), files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Feature engineering\n",
    "After looking at these spreadsheets, I realize there isn't a ton of information with which to work. My initial thought is to do some sort of a word matching procedure (e.g. see if one of the search words matches one of the words in the title (or description, or attributes). Better still, I could take the individual letters in each word of the search query and try to see if they appear consecutively in the raw string of the title, description, or attributes.\n",
    "\n",
    "Let's give that a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I will definitely want to use multiprocessing in the coming steps\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom manipulation of attributes\n",
    "The attributes file has a dump of attributes and their respective product_uid values. I want two things out of this file:\n",
    "* A concatenation of all the \"values\"; that is, all of the raw text information\n",
    "* Specifically the brand name (marked as \"MFG Brand Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The attributes are a little trickier. There may be 0 or many attributes per 1 product_uid\n",
    "# I want to concatenate all strings belonging to a particular product_uid\n",
    "\n",
    "# Data[0] = product_uid; data[1] = name; data[2] = value\n",
    "def collapse_attr(data):\n",
    "    attr = {}\n",
    "    for d in data:\n",
    "        # d is an array of form [product_uid, name, value]\n",
    "        if not np.isnan(d[0]):\n",
    "            i = str(int(d[0]))\n",
    "            # Concatenate the attribute as a string\n",
    "            # Also add the brand if it exists\n",
    "            if i in attr:\n",
    "                attr[i]['string'] = \"%s %s\"%( attr[i]['string'], str(d[2]) )\n",
    "                if d[1] == 'MFG Brand Name':\n",
    "                    attr[i]['brand'] = str(d[2])\n",
    "            else:\n",
    "                attr[i] = {'string': str(d[2])}\n",
    "                \n",
    "                if d[1] == 'MFG Brand Name':\n",
    "                    attr[i]['brand'] = str(d[2])\n",
    "                else:\n",
    "                    attr[i]['brand'] = ''\n",
    "\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the training attribute array, which we will append to the dataframe in the pipeline\n",
    "attr = pd.read_csv(f_attr)\n",
    "ATTR_ARR = collapse_attr(np.array(attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for processing the strings\n",
    "These will format the strings, add alternate suffixes, and add some common abbreviations if applicable. Since we're dealing with Home Depot data, we have a general idea of what types of abbreviations we might encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a word, return all forms of it and its abbreviations\n",
    "def abbrev(s):\n",
    "    abrv_groups = [\n",
    "        [\"'\", \"in\", \"inches\", \"inch\"],\n",
    "        [\"pounds\", \"pound\", \"lbs\", \"lb\"],\n",
    "        [\"sqft\", \"sq\", \"sf\", \"square\", \"squared\", \"foot\", \"feet\", \"\\\"\", \"ft\", \"inch\", \"inches\", \"in\", \"'\"],\n",
    "        [\"cf\", \"cu\", \"cubic\", \"cubed\", \"inch\", \"foot\", \"feet\", \"'\", \"\\\"\", \"ft\", \"in\", \"inches\"],\n",
    "        [\"gal\", \"gallon\", \"gallons\"],\n",
    "        [\"g\", \"gram\", \"grams\", \"kg\", \"kilogram\", \"kilo\"],\n",
    "        [\"oz\", \"ounces\", \"ounce\"],\n",
    "        [\"cm\", \"centimeters\", \"centimeter\"],\n",
    "        [\"m\", \"meter\", \"meters\"],\n",
    "        [\"mm\", \"milimeter\", \"millimeter\", \"milimeters\", \"millimeters\"],\n",
    "        [\"a\", \"amp\", \"amps\", \"ampere\", \"amperes\"],\n",
    "        [\"w\", \"watt\", \"watts\"],\n",
    "        [\"v\", \"volt\", \"volts\"],\n",
    "        [\"whirpool\",\"whirlpool\", \"whirlpoolga\", \"whirlpoolstainless\",\"stainless\"],\n",
    "        [\"and\", \"&\", \"+\", \"&amp;\"],\n",
    "        [\"x\", \"by\", \"*\"],\n",
    "        [\"deg\", \"degree\", \"degrees\", \"°\", \"angle\"],\n",
    "        ['dia', 'diameter']\n",
    "    ]\n",
    "    \n",
    "    # If we can match the word in an abbreviation group, return the whole group\n",
    "    for g in abrv_groups:\n",
    "        if s in g:\n",
    "            return g\n",
    "        \n",
    "    # If we can't match anything just return an empty array\n",
    "    return []\n",
    "\n",
    "# Turn the string into a series of words\n",
    "def process_string(s):\n",
    "    \n",
    "    __words = np.array(s.split(\" \"))\n",
    "    \n",
    "    # Split by special, but include those characters\n",
    "    # This regex splits by the characters [', \", /, *, -], but INCLUDES those characters\n",
    "    _words = list(np.hstack(map(lambda i: re.split(r\"(plus|[('\\\"\\-*/)])\", i), __words)))\n",
    "\n",
    "    words = _words\n",
    "    \n",
    "    # Get rid of commas\n",
    "    words = map(lambda x: x.replace(',', ''), words)\n",
    "    # Get rid of semicolons\n",
    "    words = map(lambda x: x.replace(';', ''), words)\n",
    "    # Get rid of colons\n",
    "    words = map(lambda x: x.replace(':', ''), words)\n",
    "    # Get rid of periods\n",
    "    words = map(lambda x: x.replace('.', ''), words)\n",
    "    # Get rid of blanks\n",
    "    words = filter(lambda x: x != ' ' and x != '', words)\n",
    "    return words\n",
    "\n",
    "\n",
    "def pre_process_strings(query):\n",
    "    \n",
    "    # Lowercase all the things\n",
    "    query = str(query.lower())\n",
    "    \n",
    "    # Split the query into an array of char arrays\n",
    "    query_words = process_string(query)\n",
    "\n",
    "    return query_words\n",
    "\n",
    "\n",
    "# This function processes strings like \"4x4\" or \"4'x4'\"\n",
    "def process_x_by(s):\n",
    "    if any(i.isdigit() for i in s) and \"x\" in s:\n",
    "        new_s = list(filter(lambda x: x!='', s.split(\"x\"))); new_s.append(s); new_s.append(\"x\")\n",
    "        return new_s\n",
    "    else:\n",
    "        return [s]\n",
    "\n",
    "# Split strings that have unit suffixes (e.g. 10in, 50g, etc)\n",
    "def process_unit_suffixes(s):\n",
    "    strings = [\"mm\", \"cm\", \"m\", \"g\", \"kg\", \"in\", \"ft\", \"a\", \"w\", \"v\", \"oz\", \"gal\", \"cf\"]\n",
    "    # Inefficient but I can't think of a better way\n",
    "    for i in strings:\n",
    "        # If any of the above strings is in s, return that string + the number\n",
    "        if i in s and any(j.isdigit() for j in s):\n",
    "            arr = list(filter(lambda x: x!='', s.split(i))); arr.append(i); arr.append(s)\n",
    "            return arr\n",
    "\n",
    "    return [s]\n",
    "\n",
    "# Get a list of words similar to the word if applicable\n",
    "# This will get called with a word in the QUERY\n",
    "def extension_words(word):\n",
    "    \n",
    "    # Make damn sure everything is lower case\n",
    "    w = word.lower()\n",
    "    \n",
    "    # Process strings of the form \"AxB\"\n",
    "    ret_words = process_x_by(w)\n",
    "    \n",
    "    # Include abbreviation words\n",
    "    abbr = abbrev(w)\n",
    "    \n",
    "    # Flatten array\n",
    "    ret_words = list(np.hstack([ret_words, abbr]))\n",
    "    \n",
    "    \n",
    "    # If the word is small (<4 chars), contains a number, or contains a special character,\n",
    "    #     only add s and return\n",
    "    if any(i.isdigit() for i in w) or len(list(word)) < 4 or any(i in w for i in [\"-\", \"*\", \"'\", \"\\\"\", \"/\"]):\n",
    "        ret_words.append(\"%ss\"%w)\n",
    "        return filter(lambda x: x!='' and x!=' ', ret_words)\n",
    "\n",
    "    \n",
    "    # A list of suffixes\n",
    "    suffixes = ['s', 'ed', 'ing', 'n', 'en', 'er', 'est', 'ise', 'fy', 'ly',\n",
    "               'ful', 'able', 'ible', 'hood', 'ess', 'ness', 'less', 'ism',\n",
    "               'ment', 'ist', 'al', 'ish', 'tion']\n",
    "    \n",
    "    # If the word ends in one of these suffixes, add the smaller version\n",
    "    # to strings; otherwise, add this to the end of the word and add that\n",
    "    for x in xrange(len(suffixes)):\n",
    "        l = len(suffixes[x])\n",
    "        if w[-l:] == suffixes[x]:\n",
    "            ret_words.append(w[0:-l])\n",
    "        else:\n",
    "            ret_words.append(w+suffixes[x])\n",
    "\n",
    "    return filter(lambda x: x!='' and x!=' ', ret_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for doing word searches\n",
    "These will determine if words in the query are in the matching string. We want to know three basic things:\n",
    "* Does the string contain *any* of the query words?\n",
    "* What fraction of the query words are in the matching words?\n",
    "* What fraction of the chars making up query words are found in the matching words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine if the word is in the comparison string\n",
    "#   @returns 1 or 0\n",
    "def match_word(word, compare):\n",
    "    strings = extension_words(word)\n",
    "    if not strings: return 0\n",
    "    return min(1, sum( map(lambda s: 1 if s in compare else 0, strings ) ))\n",
    "\n",
    "# Determine the number of times the word (or any version of it) matches a string\n",
    "#   @returns array of match counts\n",
    "def match_word_count(word, compare):  \n",
    "    strings = filter( lambda x: x!='' and x!=' ', extension_words(word) )\n",
    "    if not strings: return 0\n",
    "    return max( map(lambda s: compare.count(s) , strings ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "## STRING MATCHING\n",
    "##=========================================================\n",
    "\n",
    "# Get the number of unique words that are matched\n",
    "def matched_words_string(query, to_match):\n",
    "    query_words = pre_process_strings(query)\n",
    "    return sum( map(lambda x: match_word(x, to_match.lower()), query_words) ) if query_words else 0\n",
    "    \n",
    "    \n",
    "# Get the count of all words matched (i.e. if a word is matched more than once, it is counted multiple times)\n",
    "def count_matched_words_string(query, to_match):\n",
    "    query_words = pre_process_strings(query)\n",
    "    return sum( map(lambda x: match_word_count(x, to_match.lower()), query_words) )\n",
    "\n",
    "## Word matching to the words in the string\n",
    "def matched_words_words(query, to_match):\n",
    "    query_words = pre_process_strings(query)\n",
    "    to_match_words = to_match.split(\" \")\n",
    "    sums = map(lambda y: sum( map(lambda x: match_word(x, to_match.lower()), query_words) ), \\\n",
    "                to_match_words) if query_words else 0\n",
    "    return sum(sums)\n",
    "\n",
    "# Count of words matching the words in the string\n",
    "def count_matched_words_words(query, to_match):\n",
    "    query_words = pre_process_strings(query)\n",
    "    to_match_words = to_match.split(\" \")\n",
    "    counts = map(lambda y: sum( map(lambda x: match_word_count(x, to_match.lower()), query_words) ), \\\n",
    "                to_match_words) if query_words else 0\n",
    "    return sum(counts)\n",
    "        \n",
    "\n",
    "\n",
    "## QUERY MATCHING\n",
    "##=========================================================\n",
    "\n",
    "# Whether or not the whole query is in the string\n",
    "def matched_query(query, to_match):\n",
    "    return query in to_match\n",
    "\n",
    "# How many times the whole query is in the string\n",
    "def count_matched_query(query, to_match):\n",
    "    return to_match.count(query)\n",
    "\n",
    "# Whether or not the last word of the query is in the to_match string\n",
    "def last_word(query, to_match):\n",
    "    last_q = query.split(\" \")[-1]\n",
    "    return 1 if last_q in to_match else 0\n",
    "\n",
    "# Whether or not a word from the query is the FIRST word in the to_match string\n",
    "def first_word(query, to_match):\n",
    "    first_q = query.split(\" \")[0]\n",
    "    return 1 if first_q in to_match else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Feature Engineering Pipeline\n",
    "I will start by engineering new features and removing the long strings in my data set. Specifically, I want to add\n",
    "\n",
    "* Match rates of query relating to title and description (determined by char_match_fraction function)\n",
    "* String length columns of query, description, and title columns\n",
    "\n",
    "I will go ahead and build a new training set based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# POOL lambda functions (need to be defined outside the function that calls them)\n",
    "# With multiprocessing, we can't use lambda, so I will define some basic functions here\n",
    "#================================================================================\n",
    "\n",
    "# Attribute stuff\n",
    "def lambda_in_attr(a):\n",
    "    return ATTR_ARR[str(int(a))]['string'] if str(int(a)) in ATTR_ARR else ''\n",
    "def lambda_brand(a):\n",
    "    return ATTR_ARR[str(int(a))]['brand'] if str(int(a)) in ATTR_ARR else ''\n",
    "\n",
    "# Lengths\n",
    "def lambda_char_len(a):\n",
    "    return float(len(list(str(a))))\n",
    "def lambda_word_len(a):\n",
    "    return float(len(str(a).split(\" \")))\n",
    "\n",
    "# Matched words\n",
    "def l_matched_words_string(a):\n",
    "    return float(matched_words_string( str(a[0]), str(a[1]) ))\n",
    "def l_count_matched_words_string(a):\n",
    "    return float(count_matched_words_string( str(a[0]), str(a[1]) ))\n",
    "def l_matched_words_words(a):\n",
    "    return float(matched_words_words( str(a[0]), str(a[1]) ))\n",
    "def l_count_matched_words_words(a):\n",
    "    return float(count_matched_words_words( str(a[0]), str(a[1]) ))\n",
    "\n",
    "# Matched queries\n",
    "def l_matched_query(a):\n",
    "    return matched_query( str(a[0]), str(a[1]) )\n",
    "def l_count_matched_query(a):\n",
    "    return float(count_matched_query( str(a[0]), str(a[1]) ))\n",
    "\n",
    "# Binaries\n",
    "def l_last_word(a):\n",
    "    return last_word( str(a[0]), str(a[1]) )\n",
    "def l_first_word(a):\n",
    "    return first_word( str(a[0]), str(a[1]) )\n",
    "\n",
    "#================================================================================\n",
    "## DATA PIPELINE\n",
    "#================================================================================\n",
    "# Given the data (train or test) and description files,\n",
    "# perform a series of operations to produce a data set on which we can do ML\n",
    "def feature_pipeline(data_file, **kwargs):\n",
    "    \n",
    "    # Define my multiprocessing pool and start the timer\n",
    "    POOL = Pool(maxtasksperchild=1000)\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    #============\n",
    "    # Read files\n",
    "    #============\n",
    "    \n",
    "    # Read the initial train.csv and join it to product descriptions\n",
    "    _df = pd.read_csv(data_file) #, encoding=\"ISO-8859-1\")\n",
    "\n",
    "    # Add in descriptions because they are 1:1\n",
    "    df = pd.merge(_df, pd.read_csv(f_desc), how='outer')\n",
    "    \n",
    "    # If there is an attribute for a product uid, join it\n",
    "    df['attr'] = POOL.map(lambda_in_attr, df['product_uid'])\n",
    "    df['brand'] = POOL.map(lambda_brand, df['product_uid'])\n",
    "    \n",
    "    \n",
    "    #===========================================\n",
    "    # ADD LENGTH Columns (filter out whitespace)\n",
    "    #===========================================\n",
    "    \n",
    "    # Char lengths\n",
    "    df['desc_char_l'] = pd.Series( POOL.map(lambda_char_len, df['product_description']) )\n",
    "    df['title_char_l'] = pd.Series( POOL.map(lambda_char_len, df['product_title']) )\n",
    "    df['query_char_l'] =  pd.Series( POOL.map(lambda_char_len, df['search_term']) )\n",
    "    df['attr_char_l'] = pd.Series( POOL.map(lambda_char_len, df['attr']) )\n",
    "    df['brand_char_l'] = pd.Series( POOL.map(lambda_char_len, df['brand']) )\n",
    "    \n",
    "    # Word lengths\n",
    "    df['desc_word_l'] = pd.Series( POOL.map(lambda_word_len, df['product_description']) )\n",
    "    df['title_word_l'] = pd.Series( POOL.map(lambda_word_len, df['product_title']) )\n",
    "    df['query_word_l'] = pd.Series( POOL.map(lambda_word_len, df['search_term']) )\n",
    "    df['attr_word_l'] = pd.Series( POOL.map(lambda_word_len, df['attr']) )\n",
    "    df['brand_word_l'] = pd.Series( POOL.map(lambda_word_len, df['brand']) )\n",
    "    \n",
    "    \n",
    "    #====================\n",
    "    # ADD MATCH COLUMNS\n",
    "    #====================\n",
    "    \n",
    "    # Zip the data into tuples\n",
    "    desc_zip = np.dstack( ( np.array(df['search_term']), np.array(df['product_description']) ))[0]\n",
    "    title_zip = np.dstack( (np.array(df['search_term']), np.array(df['product_title']) ))[0]\n",
    "    attr_zip = np.dstack( (np.array(df['search_term']), np.array(df['attr']) ))[0]\n",
    "    brand_zip = np.dstack( (np.array(df['search_term']), np.array(df['brand']) ))[0]\n",
    "    \n",
    "    # Number of unique words that are matched to the comparison string (float)\n",
    "    df['desc_matched_string'] = pd.Series( POOL.map(l_matched_words_string, desc_zip ) )\n",
    "    df['desc_matched_string'] = pd.Series( POOL.map(l_matched_words_string, desc_zip ) )\n",
    "    df['title_matched_string'] = pd.Series( POOL.map(l_matched_words_string, title_zip ) )\n",
    "    df['attr_matched_string'] = pd.Series( POOL.map(l_matched_words_string, attr_zip ) )\n",
    "    df['brand_matched_string'] = pd.Series( POOL.map(l_matched_words_string, brand_zip))\n",
    "    \n",
    "    # Total number of query words matched to the comparison string (float)\n",
    "    df['desc_count_string'] = pd.Series( POOL.map(l_count_matched_words_string, desc_zip ) )\n",
    "    df['title_count_string'] = pd.Series( POOL.map(l_count_matched_words_string, title_zip ) )\n",
    "    df['attr_count_string'] = pd.Series( POOL.map(l_count_matched_words_string, attr_zip ) )\n",
    "    \n",
    "    # Whether or not the whole query (string) can be found in the comparison string (bool)\n",
    "    df['desc_query_matched'] = pd.Series( POOL.map(l_matched_query, desc_zip ) )\n",
    "    df['title_query_matched'] = pd.Series( POOL.map(l_matched_query, title_zip ) )\n",
    "    df['attr_query_matched'] = pd.Series( POOL.map(l_matched_query, attr_zip ) )\n",
    "    \n",
    "    # How many times the query is in the comparison string (float)\n",
    "    df['desc_query_count'] = pd.Series( POOL.map(l_count_matched_query, desc_zip ) )\n",
    "    df['title_query_count'] = pd.Series( POOL.map(l_count_matched_query, title_zip ) )\n",
    "    df['attr_query_count'] = pd.Series( POOL.map(l_count_matched_query, attr_zip ) )\n",
    "    \n",
    "    # Fraction of unique words matched divided by number of unique words in the query (float)\n",
    "    df['desc_frac_matched'] = df['desc_matched_string'] / df['query_word_l']\n",
    "    df['title_frac_matched'] = df['title_matched_string'] / df['query_word_l']\n",
    "    df['attr_frac_matched_query'] = df['attr_matched_string'] / df['query_word_l']\n",
    "    # Also by the attr length\n",
    "    df['attr_frac_matched_attr'] = df['attr_matched_string'] / df['attr_word_l']\n",
    "    \n",
    "    # Is the last word of the query in the comparison string? (bool)\n",
    "    df['desc_last_word'] = pd.Series( POOL.map(l_last_word, desc_zip) )\n",
    "    df['title_last_word'] = pd.Series( POOL.map(l_last_word, title_zip) )\n",
    "    \n",
    "    # Is the first word of the query in the comparison string? (bool)\n",
    "    df['desc_first_word'] = pd.Series( POOL.map(l_first_word, desc_zip) )\n",
    "    df['title_first_word'] = pd.Series( POOL.map(l_first_word, title_zip) )\n",
    "    \n",
    "    # Drop NaNs\n",
    "    copy_df = copy.deepcopy(df.dropna())\n",
    "    \n",
    "    print display(HTML(\"<font color='blue'><b>Data pipelined in %s s</b></font>\"%(time.time()-start)))\n",
    "    return copy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color='blue'><b>Data pipelined in 39.05103302 s</b></font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train = feature_pipeline(f_train)\n",
    "y_train = X_train['relevance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067, 39)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Plot the Feature Distributions\n",
    "As a sanity check, it is good to check out the first few lines of my data frame and also to graph the features to make sure there are actual distributions of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution (histogram) of my features\n",
    "def plot_hist(col, name):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    plt.title('%s' %name, fontsize=15)\n",
    "    #fig.colorbar(cax)\n",
    "    plt.hist(col)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def run_feature_plots(df):\n",
    "    # Feature plots\n",
    "    skip_cols = ['id', 'product_uid', 'relevance','search_term', 'brand',\n",
    "                     'product_title','product_description','attr']\n",
    "    \n",
    "    features = list(df.drop(skip_cols, axis=1).columns.values)\n",
    "    # Plot a bunch of stuff\n",
    "    dim = len(features)/3 + 1 if len(features)%3 > 0 else len(features)/3\n",
    "\n",
    "    f, axarr = plt.subplots(dim, 3, figsize=(16,20))\n",
    "    plt.tight_layout(pad=3)\n",
    "    \n",
    "    for i in range(0, dim):\n",
    "        # For each row\n",
    "        for j in range(0, 3):\n",
    "            # For each element in the row\n",
    "            if (i*3 + j) < len(features):\n",
    "                # As long as the chart exists in the tuple\n",
    "                axarr[i][j].hist( df[ features[i*3+j] ], color='orange' )\n",
    "                axarr[i][j].set_title( features[i*3+j], fontsize=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_feature_plots(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Learning\n",
    "A few notes about the distributions:\n",
    "\n",
    "* The string length columns look to be distributed pretty nicely\n",
    "* The description matches are heavily favored to the right (meaning the strings match well); we would expect this from a search engine\n",
    "* The relevance scores are also heavily favored to the right (again, we expect this engine to work reasonably well, so this makes makes sense)\n",
    "\n",
    "Everything so far looks reasonable. Now I will go ahead and set up a machine learning pipeline to test some algorithms on the training/test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pipeline Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Define my custom pipeline\n",
    "class CustomPipeline(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        drop_cols = ['id', 'product_uid', 'relevance','search_term', 'brand',\n",
    "                     'product_title','product_description','attr']\n",
    "        new_df = df.drop(drop_cols, axis=1).values\n",
    "        return new_df\n",
    "    \n",
    "# This is a \n",
    "class TextPipeline(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        # Convert dict into a string\n",
    "        return data_dict[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor as BR\n",
    "from sklearn import pipeline, grid_search\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "## Use a random forest\n",
    "rfr = RandomForestRegressor(n_jobs=-1, n_estimators=400, max_depth=15, verbose=0)\n",
    "\n",
    "# Use tf-idf sk-learn functions to vectorize the documents\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "# After tf-idf, reduce dimensionality of the vector\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "\n",
    "## Define the pipeline\n",
    "_pipeline = pipeline.Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('cst',  CustomPipeline()),\n",
    "            ('txt1', pipeline.Pipeline([\n",
    "                ('s1', TextPipeline(key='search_term')),\n",
    "                ('tfidf1', tfidf), \n",
    "                ('tsvd1', tsvd)\n",
    "            ])),\n",
    "            ('txt2', pipeline.Pipeline([\n",
    "                ('s2', TextPipeline(key='product_title')), \n",
    "                ('tfidf2', tfidf),\n",
    "                ('tsvd2', tsvd)\n",
    "            ])),\n",
    "            #('txt3', pipeline.Pipeline([('s3', TextPipeline(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n",
    "            ('txt4', pipeline.Pipeline([\n",
    "                ('s4', TextPipeline(key='brand')),\n",
    "                ('tfidf4', tfidf), \n",
    "                ('tsvd4', tsvd)\n",
    "            ]))        \n",
    "        ],\n",
    "        transformer_weights = {\n",
    "            'cst': 1.0,\n",
    "            'txt1': 0.5,\n",
    "            'txt2': 0.25,\n",
    "            #'txt3': 0.05,\n",
    "            'txt4': 0.5\n",
    "        },\n",
    "        n_jobs = -1\n",
    "    )), \n",
    "    ('rfr', rfr)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Define the loss function; this is a custom root-MSE (RMSE) function with tighter errors\n",
    "def f_mse(y, y_pred):\n",
    "    return mean_squared_error(y, y_pred)**0.5\n",
    "RMSE = make_scorer(f_mse, greater_is_better=False)\n",
    "\n",
    "# Param grid for GridSearch\n",
    "param_grid = { 'rfr__max_features': [10],'rfr__max_depth': [20] }\n",
    "\n",
    "# Arguments for GridSearch\n",
    "grid_search_args = {\n",
    "    'estimator': _pipeline,\n",
    "    'param_grid': param_grid,\n",
    "    'n_jobs': -1,\n",
    "    'cv': 4,\n",
    "    'verbose': 0,\n",
    "    'scoring': RMSE\n",
    "}\n",
    "\n",
    "# Define the model\n",
    "model = grid_search.GridSearchCV(**grid_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred while tokenizing input file /usr/lib/python2.7/encodings/utf_8.pyc\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py:497: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for name, trans in self.transformer_list)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 5 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d0186d138015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# RUN GridSearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"GridSearchCV completed in %s s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    810\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    747\u001b[0m                     \u001b[1;31m# Convert this to a JoblibException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m                 \u001b[1;31m# Kill remaining running processes without waiting for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: function takes exactly 5 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "# RUN GridSearch\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print \"GridSearchCV completed in %s s\"%(time.time()-start)\n",
    "print \"Best parameters found by grid search: %s\"%model.best_params_\n",
    "print \"Best CV score: %s\"%model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Test Set\n",
    "Now I will move over to the test set. I will predict based on the model I just generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color='blue'><b>Data pipelined in 66.6978371143 s</b></font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test = feature_pipeline(f_test)\n",
    "\n",
    "# Separate the ids\n",
    "df_test_ids = df_test['id']\n",
    "\n",
    "# Need to add this column temporarily; it will get dropped in the pipeline\n",
    "df_test['relevance'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Predict test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Predict!\n",
    "test_y = model.predict(df_test)\n",
    "final_y = map(lambda x: 1 if x < 1. else 3 if x > 3. else x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Look at distributions\n",
    "After looking at the data, I want to look at the distribution and compare it to the one from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hist(final_y, 'Scores in Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hist(train_y, 'Normalized Relevance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Test mean: %s, std: %s\"%(np.mean(final_y), np.std(final_y))\n",
    "print \"Training mean: %s, std: %s\"%(np.mean(train_y), np.std(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7: Submission\n",
    "Now I am finally ready to write the submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"submission4\"\n",
    "\n",
    "path = \"%s/%s.csv\"%(DATADIR, file_name)\n",
    "pd.DataFrame({\"id\": df_test_ids.apply(int), \"relevance\": test_y}).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
